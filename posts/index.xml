<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 华彬闳的Blog</title>
    <link>https://ooneko.github.io/posts/</link>
    <description>Recent content in Posts on 华彬闳的Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 26 Dec 2019 16:34:07 +0800</lastBuildDate>
    
	<atom:link href="https://ooneko.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>如何利用HAProxy 代理 MySQL Master-Slave Replication</title>
      <link>https://ooneko.github.io/posts/mysql_replication_with_haproxy/</link>
      <pubDate>Thu, 26 Dec 2019 16:34:07 +0800</pubDate>
      
      <guid>https://ooneko.github.io/posts/mysql_replication_with_haproxy/</guid>
      <description>背景 我有一个MySQL Master-Slave Replication, 想要通过HAProxy代理, 做读写分离.
写流量给到Master 节点, 读流量给到Slave 节点.
首先我应该由一个HAProxy的配置, 我想应该这样写(伪配置):
listen mysql bind *:3316 mode tcp ... server 192.168.1.111 192.168.1.111:3306 check server 192.168.1.112 192.168.1.112:3306 check server 192.168.1.113 192.168.1.113:3306 check  很明显, 这么写仅仅只实现了流量的分发, 但并不能实现我的需求: 把写流量给Master, 读流量给Slave 节点.
那么问题来了,首先我要能够识别Master Slave 节点, 才能有接下来的流量分离.
HAProxy有个配置项叫做 mysql-check. 但是这里并不能用它去做Master-Slave的检测,因为这个option只提供存活检测. 只要能够连上,就代表这个mysql后端是Health OK的.
这还是不符合我的需求.
MySQL 如果能够通过tcp-check 检测是Master还是Slave就好了.
既然这样, 写一个TCP-check Wrapper 不就可以了?
TCP-Check-Wrapper 这个Wrapper应该监听在TCP端口上,并以守护进程的方式运行. 当HAproxy连接至其监听的端口时, 会执行相应的脚本, 并将脚本执行结果通过 TCP 连接发送至Haproxy.
代码如下: - TCP-Check-Wrapper - mysqlchk
放置好mysqlchk 脚本, 然后在每个MySQL节点上把tcp-check-wrapper服务跑起来.</description>
    </item>
    
    <item>
      <title>如何编写 ANSIBLE FILTER PLUGINS</title>
      <link>https://ooneko.github.io/posts/how_to_write_ansible_filters/</link>
      <pubDate>Tue, 22 Oct 2019 12:13:09 +0800</pubDate>
      
      <guid>https://ooneko.github.io/posts/how_to_write_ansible_filters/</guid>
      <description>什么是 ansible filter plugin ？ 先来看一段代码： union_list: {{ [1,2,3] | union([2,3,4]) }} 这段代码的意思是想要取两个list的并集. 思考一下，如果没有union这个filter，我们该如何得到这两个list的并集？
ansible filter plugins 本质上就是 jinja2 filters，所以我在jinja2 api上找到了关于filters的定义:
 Custom filters are just regular Python functions that take the left side of the filter as first argument and the arguments passed to the filter as extra arguments or keyword arguments.
 总结一下就是：
 filter plugin 用于修改数据，通过处理 | 左边输入的参数，返回处理后的结果 filter plugin 是一个python function，可以在jinja2 templating 表达式中通过 | 调用 filter plugin 需要至少一个参数，也可以接收 0到N个额外的positional / keyword argument  创建filter plugin 刚才已经知道filter plugin 本质上是一个python function.</description>
    </item>
    
    <item>
      <title>如何测试&#34;无限循环&#34;的代码</title>
      <link>https://ooneko.github.io/posts/2019-03-05-howto-test-infinite-loop/</link>
      <pubDate>Tue, 05 Mar 2019 17:42:50 +0000</pubDate>
      
      <guid>https://ooneko.github.io/posts/2019-03-05-howto-test-infinite-loop/</guid>
      <description>在写 python 有时会遇到一些”无限循环“的代码需要测试，比如一个持续监控某个api状态的线程。很有可能会写成这样:
def watch(self): while self.running: do_something() ...  这样的话，单元测试写起来就比较奇怪了。最先想到的是把其中某个函数mock掉，通过side_effect 返回一个exception 来结束测试。
class TestCase(unittest.TestCase): def test_watch(self): do_something = mock.Mock() do_something.side_effect = [&#39;some_valuable_info&#39;, Exception] self.assertRaises(Exception, do_something)  有没有更好的方法呢？ 有.
把退出条件放到一个方法里面去，在测试的时候，通过mock掉这个方法，来达到退出条件。
def is_running(self): return self.running def watch(self): while self.is_running(): do_something() ...  这样测试起来就容易多了, 当第一次运行时，调到的is_running 是True，第二次运行调用到is_running 的时候就会退出测试。
class TestCase(unittest.TestCase): def test_watch(self): mock_is_running = mock.Mock() mock_is_running.side_effect = [True, False] watch() ...  总结一下： 几乎没有真正的‘无限循环’代码，找出它的退出条件，然后重构代码。</description>
    </item>
    
    <item>
      <title>Bash brace expansion</title>
      <link>https://ooneko.github.io/posts/2018-12-11-bash_brace_expansion/</link>
      <pubDate>Tue, 11 Dec 2018 15:17:28 +0000</pubDate>
      
      <guid>https://ooneko.github.io/posts/2018-12-11-bash_brace_expansion/</guid>
      <description>bash 中的大括号&amp;rdquo;{}&amp;ldquo;,通常用来生成一组有规律的字符串
最常用的 mkdir /tmp/test{1..3} 在执行的时候会被翻译成:
mkdir /tmp/test1 /tmp/test2 /tmp/test3  生成连续的字符或者数字用&amp;quot;..&amp;quot;
{0..12} =&amp;gt; 0 1 2 3 4 5 6 7 8 9 10 11 12 {3..-2} =&amp;gt; 3 2 1 0 -1 -2 {a..g} =&amp;gt; a b c d e f g {g..a} =&amp;gt; g f e d c b a  生成非连续的字符用逗号分隔“,”
{aa,bb,cc,dd} =&amp;gt; aa bb cc dd  当然也可以组合使用
{a,b{0..3},c} =&amp;gt; a b0 b1 b2 b3 c  当brace expation 和其他字符串一起出现时，会重复整个字符串</description>
    </item>
    
    <item>
      <title>浅谈 CentOS/RHEL 7 下的网络设备命名规则</title>
      <link>https://ooneko.github.io/posts/centos7_network_device_naming/</link>
      <pubDate>Sun, 03 Dec 2017 10:45:10 +0000</pubDate>
      
      <guid>https://ooneko.github.io/posts/centos7_network_device_naming/</guid>
      <description>使用过CentOS 7 或者RHEL 7的同学应该都见过类似 eno, em, ens 之类的网卡名称, 那么在什么情况下用什么命名方式有没有什么规则呢？ 答案是，有的。
CentOS 7 中，网卡名称通常由两个组件来决定的: systemd , biosdevname。 默认情况下，由systemd来决定网卡名称，systemd会按照以下规则来命名网卡: - 场景1：如果BIOS中存在板载网卡, 并能够提供索引，则使用eno命名，比如 eno1, 如果没有板载设备，就掉到场景2。 - 场景2：如果BIOS中存在PCI-E热插拔网卡，并提供了索引，则采用ens命名，例如ens1，如果没有则掉到场景3。 - 场景3：使用网卡的物理位置enp来命名，例如enp2s0。如果没有物理位置信息，则掉到场景5。 - 场景4：使用MAC地址命名网卡，例如enx78e7d1ea46da。不过默认不启用这个特性。 - 场景5：如果123场景都没有命中，则使用传统的命名方式eth来命名。
到这里，有人会问，那么em，pXpY之类的命名规则去哪了？
嗯，还有一种情况就是biosdevname。
如果系统中安装并启用了biosdevname , 并且系统的BIOS版本大于或等于 SMBIOS version 2.6。通常Dell的机器SMBIOS 都是大于2.6的，所以经常能在Dell的服务器上看到em1,p3p4这样的设备。systemd 和 biosdevname 这两套命名规则不能共存，在同一时间只可能用一种，所以不会出现同时使用两种命名规则的情况。
biosdevname 的命名规则:
   Device Name     板载网卡 em[1234]   PCI网卡 p&amp;lt;slot&amp;gt;p&amp;lt;ethernet port&amp;gt;   虚拟网卡 p&amp;lt;slot&amp;gt;p&amp;lt;ethernet port&amp;gt;_&amp;lt;virtual interface&amp;gt;    参考链接: - https://access.</description>
    </item>
    
  </channel>
</rss>